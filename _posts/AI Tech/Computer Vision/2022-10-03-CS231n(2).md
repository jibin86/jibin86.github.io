---
title:  "[Computer Vision] 2. Image Classification"
categories: [AI Tech, Computer Vision]
tags: [CS231n, CNN]
---
스탠포드대학에서 발표한 CNN 강의 영상을 듣고 자료를 정리했습니다.

[Lecture 2 \| Image Classification](https://youtu.be/OoUX-nOEjG0)<br>

# Image Classification이란
컴퓨터 비전에서 가장 중요한 Task

이미지가 주어졌을 때 시스템에서 미리 label해놓은 분류된 이미지 집합 중, 어디에 속할지 컴퓨터가 판단하는 것
 
<br>

## Semantic Gap 문제
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FW8s0V%2FbtrNUA6yVPc%2FpHmrM8zBTIWwc1eX5rIQj1%2Fimg.png)
카메라 각도나 밝기, 객채의 행동 혹은 가려짐 등 여러차이로 인해 이미지의 픽셀 값이 달리 읽어 사물을 다르게 인식하는데, 고양이라는 객체와 컴퓨터가 보는 픽셀의 숫자들 간에 격차가 생김 

<br>

## 방법1

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FboMlNS%2FbtrNSCkAo53%2FkuaAy6gkyjX4FlGJ9iHrNk%2Fimg.png)

객체의 특징을 규정한다. &rarr; 성능 좋지 못하고 다른 데이터에 적용시키기에 비효율적
 
<br>

## 방법2

**데이터 중심 접근 방법(Data-Driven Approach)**

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FQtHfB%2FbtrNSVjznEL%2FHBUqytfPIMQftL6iIPv8G0%2Fimg.png)

객체의 특징을 규정하지 않고, 다양한 사진들과 label을 수집하고, 이를 이용해 모델을 학습하여 사진을 새롭게 분류하는 방식



<br>
<br>


# Nearest Neighbor(NN)
입력받은 데이터를 저장한 다음 새로운 입력 데이터가 들어오면, 기존 데이터에서 비교하여 가장 유사한 데이터를 찾아내는 매우 간단한 방식

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtEs6L%2FbtrNSD4O1XA%2FhP10PivXYhAyc6Nlr1Xnzk%2Fimg.png)  

단점: 모든 사진의 픽셀값의 계산하기 때문에 예측 과정에서 소요되는 시간이 상당하다.

<br>

## 방법: K-Nearest Neighbors

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmSTuI%2FbtrNTBETgRs%2FVTxBaznD66ak9X3H7EsKfk%2Fimg.png)

Distance metric를 이용해서 가까운 이웃을 k개만큼 찾고, 이웃간에 투표를 하여 득표수가 많이 얻은 label로 예측하는 방법

(가장 가까운 이웃이 존재하지 않으면 흰색으로 표기된다)
<br>

<br>


![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F8wgeg%2FbtrNTz1oEbg%2FTnCDg1avWOkFcs06dFW8W0%2Fimg.png){: width='500'}

**L1 Distance**

마름모 형태

좌표계를 회전 시 거리값이 달라짐

<br>


**L2 Distance(Euclidean Distance)**

원형의 형태

좌표계를 회전해도 거리값은 좌표의 영향을 받지 않는다.
<br>

<br>


## KNN이 이미지 분류에 실제로 사용되지 않는 이유

1. 너무 느림

2. L1, L2 Distance는 이미지 거리 구하는데 적합하지 않다.

![image](https://user-images.githubusercontent.com/89712324/221607509-7a5f6fc4-4f86-4d56-9756-a41124a3a6bf.png)

부분적인 차이를 감지하기 어렵다

<br>

<br>


# Linear Classification(선형분류)
Neural Network(NN)과 Convolution Neural Network(CNN)의 기반 알고리즘으로 매우 중요하다.

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbAgYkX%2FbtrNVm1jZhW%2FC2FfamAQ5fkWiG5Y5c1Vf0%2Fimg.png){: width='500'}  
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcfTPxC%2FbtrNSEQcEWI%2FvQPX2Bf2Z4QjIXq8zb3N1K%2Fimg.png){: width='500'}

위 고양이 사진(2x2)을 예시로 입력(X)을 받으면 , 가중치 파라미터(W)와 곱하여 카테고리 score 값(f(x,w))인 10을 만든다. score값이 높을수록 고양이일 확률이 높다.

W*x 에 bias(편향값)을 더하는데, bias는 입력과는 직접적인 관계를 가지지 않으나 이미지 라벨의 불균형한 상태 보완하기 위해 사용된다.

## Interpreting a Linear Classifier
가중치 행렬의 행벡터를 가지고 다시 이미지로도 나타낼 수 있다.  
![image](https://user-images.githubusercontent.com/89712324/221607018-1f621f93-4c40-4f6c-9291-9e1cfb53a7e2.png)  
![image](https://user-images.githubusercontent.com/89712324/221607110-1c1554fe-f0b9-410c-943b-fabec7c0bb47.png)

위 사진에서 Linear Classifier는 각 클래스를 구분해주는 선형 경계 역할을 한다.

<br>


## Linear Classifier의 단점

이미지 변동이 있어도 그것의 평균을 결과로서 보여준다.

그래서 말 카테고리의 이미지를 보면 말의 머리가 두개가 나타난다.  
![image](https://user-images.githubusercontent.com/89712324/221606540-0c8b6cf3-3b38-4f42-bfa5-f1f7968b8cc8.png)

**Multimodal problem**: 선형으로 분류할 수 없는 데이터에 사용하기 어렵다.  

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbi620w%2FbtrNSNTEkoi%2F8xuiW41NKc1VanisSB3WeK%2Fimg.png)


<br>

# KNN과 Linear Classifier의 차이점
**KNN**  

시작할 때 파라미터가 없다.

테스트 할 때 전체 train set을 가지고 테스트를 한다.

<br>


**Linear Classifier**  

테스트 할 때 train set의 전체 데이터는 필요없고 train의 결과인 w을 가지고 테스트를 하므로 KNN보다 효율적이다.

