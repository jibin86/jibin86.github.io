---
title:  "[Computer Vision] Object Detection: YOLO 논문 리뷰"
categories: [AI Tech, Computer Vision]
tags: [CS231n, CNN, YOLO]
---

# Object Detection이란?

- 이미지 내 여러 객체 탐지하는 것이다.
- Output으로 bounding box를 Return 한다.

<br>

## Object Detection Milestones
- one-stage detector
    - YOLOv1 - SSD - YOLO9000 - Retina Net - YOLOv3
- two-stage detector
    - RCNN - SPP Net - Fast RCNN - Faster RCNN - RFCN - Pyramid Networks - Mask RCNN

<br>
<br>


# YOLO (You Only Look Once)

- 전체 이미지를 보는 횟수가 1회라는 의미이다.
1. **Unified**: classification + Localization 단일화하였다.
2. **Real-Time**: 속도를 개선하였으며 Faster RCNN보다 속도가 빠르다.
- Main Contribution
    1. Object Detection을 regression problem으로 관점을 전환하였다.
    2. Unified Architecture: 하나의 신경망으로 Classification과 Localization을 예측하였다.
    3. 기존 모델보다 빠른 속도를 내도록 개선하였다.
    4. 여러 도메인에서 object detection이 가능해졌다.

<br>
<br>


## 1. Unified Detection

![image](https://user-images.githubusercontent.com/89712324/221516712-98245b44-65c7-4109-8801-4e26116bc379.png){: width='500'}

![image](https://user-images.githubusercontent.com/89712324/221518895-e4833be4-f7f9-440b-bfb5-36b3d7bfaae7.png)

1. input 이미지를 S X S 그리드로 나눈다.
2. Bounding Box regression과 그리드 별로 Class probability를 계산한다. 
3. 객체를 발견한다.

- S: 그리드 size
- B: 각 grid cell 마다 예측할 bounding box의 개수
- C: 전체 고려할 클래스의 개수
- x, y: bounding box의 중심 좌표
- w, h: input image size
- pc: P(객체가 bounding box에 있으면 1, 없으면 0) * IOU


<br>


**레이어 구성**  
![image](https://user-images.githubusercontent.com/89712324/221567883-56ff7147-8104-4aa2-a940-3633376d8195.png)  
- 24개의 conv layers + 2개의 fc layer    
  - 20 conv layer: pretrained
  - 4 conv layer: fine-tuned

- Fast Yolo는 9 conv layer + fc layer의 레이어층을 가지고 있다.
- reduction layer => 연산량 감소시킴


<br>
<br>

## 2. Training Stage

![image](https://user-images.githubusercontent.com/89712324/221613783-cae11101-ef18-4492-bb8d-1c4b87627ba7.png)

- Red Bounding Box: GroundTruth: 객체의 위치를 나타내는 정답 Bounding box

- Blue Bounding Box: GroundTruth Box와 관련있는 그리드 셀

- IOU가 가장 높은 Bounding Box 1개만 사용

  - IOU는 GT와 예측된 Bounding Box가 얼마나 겹쳐져 있는가를 나타낸다.

- **Loss function**: Mean Squared Error
    ![image](https://user-images.githubusercontent.com/89712324/221568006-56a5f55b-bcf2-4cc2-9b30-fc9aa5cd8f03.png)

<br>
<br>



## 3. Inference Stage

![image](https://user-images.githubusercontent.com/89712324/221568137-ed25b3de-b430-4d3c-b85b-a833198ebd3c.png)

- 그리드 1개당 bbox 2개 * 그래드 개수 = 2 * 7*7 = 98
- 객체 당 bbox 많아지므로 NMS 적용해야한다.
    
    ![image](https://user-images.githubusercontent.com/89712324/221517022-dcf1a91d-e84c-4935-9b85-791888bed1f4.png)
    
    - NMS: 가장 예측력 좋은 박스만 남기기
    - 클래스 별로 IOU 값 높은 박스 선택
    


<br>
<br>


## 4. Experiment

![image](https://user-images.githubusercontent.com/89712324/221517065-65c6807f-5b71-47cc-9d72-fd1ecc1628f6.png){: width="300"}


속도: Fast Yolo >> Yolo >> DPM, RCNN 계열

성능: Faster-RCNN > Fast-RCNN > Yolo >> DPM


<br>

![image](https://user-images.githubusercontent.com/89712324/221517150-22b59df1-9868-4c5f-a40b-f81ca3b09183.png){: width="300"}

Fast RCNN 과 Yolo의 Error 비교

Fast RCNN과 비교하였을 때, Yolo background error가 4.75로 감소하였고, False positive(아무것도 없는데 있다고 나오는 것)도 감소하였다.

Fast RCNN + YOLO 결합 모델은 mAP 3.2 % 만큼 향상하였다.


<br>

![image](https://user-images.githubusercontent.com/89712324/221517178-1ae3b2cb-79a8-4385-a8cf-140563e8005b.png)

Robust하게 Detection하므로 여러 도메인에서 object detection이 가능하다.

VOC2007, Picasso, People-Art 데이터에서 다른 모델보다 높은 정확도를 가지고 있다.

<br>
<br>


## 5. Limitation

1. 작은 물체에 대해서는 탐지 성능이 낮다.
    - 객체의 크기가 크면 bbox 간의 IOU값의 차이가 커져서 적절한 predictor를 선택할 수 있지만,
    - 객체의 크기가 작으면 bbox간의 IOU값의 차이가 작아서, 근소한 차이로 predictor가 결정된다.
2. 일반화된 지식이랑 다르게 object의 비율이 달라지면 detection 성능이 낮아진다.


<br><br>
<br>

---

**참고 자료**

[고려대학교 산업경영공학부 DSBA 연구실 - [Paper Review] You Only Look Once : Unified, Real-Time Object Detection](https://www.youtube.com/watch?v=O78V3kwBRBk)

