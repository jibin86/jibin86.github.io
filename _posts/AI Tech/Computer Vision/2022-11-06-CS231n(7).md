---
title:  "[Computer Vision] 11. Detection and Segmentation"
categories: [AI Tech, Computer Vision]
tags: [CS231n, CNN, R-CNN]
---
스탠포드대학에서 발표한 CNN 강의 영상을 듣고 자료를 정리했습니다.

[Lecture 11 \| Detection and Segmentation](https://www.youtube.com/watch?v=nDPWywWRIRo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=11)<br><br>

컴퓨터 비전 기술은 4가지로 구분할 수 있다.  
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbM7CHy%2FbtrQ2dVysiW%2F4TMwXIVcSJXQZa4L94ppj0%2Fimg.png){: width="500"}  
1. Semantic Segmentation
2. Classification + Localization
3. Object Detection
4. Instance Segmenation


<br>

# 1. Semantic Segmentation

![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FR4Ewl%2FbtrQ4bJIpXJ%2FXyhXRStUhTiZd3tsSkunQk%2Fimg.png){: width="500"}

- Semantic Segmentation은 픽셀로 모든 사물 구분한다.
- 전체 이미지에 하나의 카테코리를 할당하는 것이 아니라 픽셀 별로 카테고리를 할당한다.
- 단점: 객체들의 개수는 파악할 수 없다.
    - 두 마리 소도 Cow 카테고리로 묶어버림 (두 마리 소라고 구분 못함)
    - instance segmentation에서 단점 해결함

<br>

  
## 방법1 **Sliding Window**
    
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcsH4a7%2FbtrQ2Sjm3vt%2FgiBS6zu0DyHhYkaE0N71Fk%2Fimg.png){: width="500"}

1. 이미지를 작은 patch들로 쪼갠다
2. 기존 이미지 분류했던 것처럼 각각의 patch들로 classification(patch의 중심 픽셀이 의미하는 카테고리가 뭘까?)을 진행한다. 
- 단점
    1. 매 patch 픽셀 마다 분류 연산 → 계산적으로 비용이 많이 든다
    2. patch 마다 겹쳐지는 부분이 많아 같은 Conv layer을 지날 수가 있게 된다.
    3. Conv layer에 넣고 출력되는 모든 픽셀에 score 적용 → spatial size를 유지해야하므로 계산 비용 크다

<br>

<br>


## 방법2 **Fully Convolutional Network**
    
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCi0zj%2FbtrQ1njQKhH%2FkzlDG6IqnvKYNQ4p3TC8Wk%2Fimg.png)

- 전체 이미지를 Conv Layer에 넣는다.
- 모든 픽셀에 대해서 분류 연산을 해야한다
- **단점**
    - Convolution들이 input 이미지와 같은 spatial size를 유지하는데 Channel의 숫자도 커지면 → 메모리적 비용이 매우 높다.


<br>

<br>



## 개선된 방법: **Down Sampling & Up Sampling**
    
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FeOyGTC%2FbtrQ0kg3A0L%2F9IhkyRIkgMiPz9fCXcbeBK%2Fimg.png)

- 모든 Conv layer들이 input 이미지의 해상도를 유지하는 대신 원본 해상도를 가진 layers의 수를 줄이고 특성 맵을 down sampling한다. 이후에 up sampling을 하며 input 이미지의 해상도가 같도록 한다.
- 이미지 분류: FC-Layer : Spatial Resolution을 키운다 → input 이미지의 해상도와 같다.
- spatial size가 작은 feature map이 많이 존재하여 깊은 Network를 형성한다.
- **Down Sampling 방법**: Max Pooling, Strided Convolution 사용
- **Up Sampling 방법**: Unpooling, Max Unpooling, Transpose Convolution 사용


<br>

### **Unpooling:**  
  ![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FuDAlx%2FbtrQ0Hwlvbv%2FkWSbsz3bImHfwEvzU227Qk%2Fimg.png)
  1. Neareset Neighbor Unpooling
  2. Bed of Nails

<br>

### **Max Unpooling**
    
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb3iKt5%2FbtrQ5kzCIMf%2FKDlx2fB59clko2Z3fYNU51%2Fimg.png)

- Max pooling과 Max Unpooling 대칭적으로 사용할 수 있다
- max pooling 했던 곳과 같은 곳에 max unpooling 한다

<br>


### **Transpose Convolution:**
    
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FvKBNS%2FbtrQ1LdKQ0u%2FWAbGTM2NAMMgVSIRfOVK81%2Fimg.png){: width="300"} ![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlgL09%2FbtrQ0XljYNr%2Fnhk5oWgB6WlIoAzhYviJhk%2Fimg.png){: width="400"}

- Convolution을 거꾸로 하는 개념
- 학습을 통해 upsampling을 한다

<br>
<br>


# 2. Classification + Localization

![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGb1nI%2FbtrQ4bbRwl6%2FVgtNMOQwr00Kn1ZbcBOO80%2Fimg.png){: width="500"}

- 물체를 구별하는 것 뿐만 아니라 물체의 위치까지 파악한다.
    - 물체를 찾아서 bounding box로 표시한다.
    - 두 가지 output, loss 존재한다.
        - class scores
        - box coordinates
        - 두 loss 합해서 gradient decent 진행한다.
  
<br>

- 아래는 Classification + Localization의 한 예이다.
  - ex) human pose estimation
    
    ![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbjPmAP%2FbtrQ2TbuX6F%2FGoDFRBfbkOUDNuqgqhets1%2Fimg.png){: width="500"} ![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FetDmt2%2FbtrQ1eULjuY%2FEtyu8t1VkVVL3mhxXWQsT0%2Fimg.png)
    
     output ⇒ positions of the joints ⇒ 어떤 포즈인지 유추할 수 있음

<br>

- **Object Detection(객체 탐지)와의 차이점**
  - Localization에서는 객체가 오직 **하나**라고 가정함
  - 다른 이미지마다 객체의 수가 달라져 미리 예측할 수 없다.



<br>

<br>

# 3. Object Detection

- 한 장의 이미지에서 **다수**의 물체를 찾고, 그 물체가 어디에 있는지 알아내는 것
- 1-stage detector, 2-stage detector로 두 가지 방식이 존재한다
    
    ![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbccWou%2FbtrQ0l1lyXI%2FGQ7rqdrmfkRjAmtjMliBo1%2Fimg.png)

<br>

<br>


    
## 방법1 Sliding Window
    
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbIJ5bY%2FbtrQ668YuUI%2F4ZXKJDkzHXJu911wnPAfT0%2Fimg.png)

- 매 patch(crop) 별로 CNN을 진행하여 분류한다.
- 문제: 이미지를 어떻게, 어떤 사이즈 등으로 쪼갤 것인가?(crop) → 수많은 방식의 crop이 존재하고, 기준도 없고, 한편으로 억지스러울 수도 있다. 그래서 이 방식을 안 쓴다

<br>

<br>


## 방법2 Region Proposals
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc52yvv%2FbtrQ6H2rLCF%2Fejp4JXX7TdKmgLqrKvvPt1%2Fimg.png)  
- region proposal network를 이용해 객체가 있을 만한 곳을 후보로 선정한다   
    → 이후에 각각 CNN을 이용하여 Classification을 진행한다
    
<br>

### 1. R-CNN
    
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FGR3YR%2FbtrQ1lTQEB9%2FbY28nIAkdtKPiQkDA4wCe1%2Fimg.png){: width="500"}

- region proposal를 이용해 찾은 객체를 CNN의 input값으로 넣어 분류한다  
<br>
- Rol(Regions of Interest)의 size가 모두 같지 않다 → 같은 모델로 훈련시킬 수 없기 때문에 → 고정된 크기로 변환하여 CNN 진행한다 → 위 사진에서는 SVM를 이용해서 Classification을 하였다.  
<br>
- R-CNN에서도 bounding box로 객체의 위치 찾기를 할 수 있다, (region proposal이 항상 정확하지 않기에 사용할 필요가 있다)  
<br>
- **문제** (모든 RoI에 대해 CNN 연산을 해야한다)
    1. 계산 비용이 크다
    2. 메모리를 많이 사용한다
    3. 학습 과정이 느리다
    4. Test Time이 느리다  
<br>
- 속도 개선 방법 → Fast R-CNN

<br>

<br>

  
### 2. Fast R-CNN
  
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcKDUOt%2FbtrQ0HiMo2I%2FXOQyHOeF9XBvxdenrYIhR0%2Fimg.png){: width="500"}

- 전체 이미지를 CNN을 이용해 고해상도 Feature map을 얻고, Feature map을 통해서 Regions of Interest를 구한다 → Rol를 ROI pooling layer를 이용하여 고정된 크기로 변환하고, CNN을 진행한다.  
<br>
- Conv 먼저하고 region proposals 얻을 때의 장점: 중복 연산 불 필요, CNN연산 재사용 가능하다.  
<br>
- 문제(problem): Test time의 수행시간이 region proposals에 따라서 달라진다.  

<br>

<br>



### 3. Faster R-CNN
    
![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmVEKM%2FbtrQ2SRdxkA%2FyefE2r8b1dWWmCuLdTqRy1%2Fimg.png)

![Untitled](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcpnhsH%2FbtrQ0YduHvn%2FKHX291MkdIDTxMbqodKzSK%2Fimg.png){: width="500"}

- Fast R-CNN 보다 빨라졌다.
- Region Proposal도 fixed function이 아닌 Region Proposal Network를 이용해 예측하는 방식이다.
  

<br>
<br>

## Region Proposal를 사용하지 않는 Network
- YOLO(You Only Look Once)
- SSD(Single Shot Detection)

<br>
<br>


# 4. Instance Segmentation

![image](https://user-images.githubusercontent.com/89712324/221510587-500b9e85-08e5-4175-9c93-dbe76ac9ba61.png){: width="300"}

- 각각의 사물 instance를 픽셀 단위로 구분한다.
- 각 픽셀은 어떠한 객체에 포함되었는가를 중심으로 사물을 분류한다.